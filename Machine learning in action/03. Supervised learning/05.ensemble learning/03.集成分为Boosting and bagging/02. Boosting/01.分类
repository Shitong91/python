Boosting系列算法里最著名算法主要有AdaBoost算法和提升树(boosting tree)系列算法。提升树系列算法里面应用最广泛的是梯度提升树(Gradient Boosting Tree)。

Boosting算法的工作机制是首先从训练集用初始权重训练出一个弱学习器1，根据弱学习的学习误差率表现来更新训练样本的权重，使得之前弱学习器1学习误差率高的训练样本点的权重变高，使得这些误差率高的点在后面的弱学习器2中得到更多的重视。然后基于调整权重后的训练集来训练弱学习器2.，如此重复进行，直到弱学习器数达到事先指定的数目T，最终将这T个弱学习器通过集合策略进行整合，得到最终的强学习器。　　

不过有几个具体的问题Boosting算法没有详细说明。

　　　　1）如何计算学习误差率e?

　　　　2) 如何得到弱学习器权重系数α

　　　　3）如何更新样本权重D?

　　　　4) 使用何种结合策略？

　　　　只要是boosting大家族的算法，都要解决这4个问题。那么Adaboost是怎么解决的呢？


